import os
import sys
import tqdm
import torch
import random
import datetime

import numpy as np
import torch.nn as nn
import matplotlib.pyplot as plt
import torch.nn.functional as F
from torch.autograd import Variable

from tensorboardX import SummaryWriter
from torch.utils.data import DataLoader, Dataset
from sklearn.model_selection import train_test_split
import torchvision

import argparse

parser = argparse.ArgumentParser('test for general adversarial training')
parser.add_argument('--seed', type=int, default=0, help='random seed')
parser.add_argument('--lr', type=float, default=5e-4, help='learning rate')
parser.add_argument('--lr_cnn', type=float, default=5e-3, help='learning rate for cnn model')
parser.add_argument('--batch_size', type=int, default=1, help='batch size for training')
parser.add_argument('--batch_size_rl', type=int, default=1, help='')

parser.add_argument('--epsilon', type=float, default=0.1, help='bounded noise')
parser.add_argument('--alpha', type=float, default=100, help='trade-off of multiplier on gfv')
parser.add_argument('--beta', type=float, default=0.1, help='trade-off of multiplier on accuracy')

parser.add_argument('--num_epoch', type=int, default=1, help='number of training epoch')
parser.add_argument('--num_steps', type=int, default=10, help='training time steps')
parser.add_argument('--start_time', type=int, default=1e3, help='time step to start learning')
parser.add_argument('--start_time_classfier', type=int, default=1e4, help='time step to start learning for the classifier')

parser.add_argument('--z_dim', type=int, default=100, help='dimension of random variable generated by G')
parser.add_argument('--gfv_dim', type=int, default=64, help='dimension of the global feature vector')

parser.add_argument('--action_lim', type=float, default=1., help='action limitation')

parser.add_argument('--dataset', type=str, default='mnist', choices=['mnist', 'fashion-mnist', 'cifar', 'stl10'],
                    help='The name of dataset')
args = parser.parse_args()

torch.manual_seed(args.seed)
def get_device():
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    return device
device = get_device()
print(device)
print(args.dataset)

if args.dataset == 'cifar' or args.dataset == 'stl10':
    args.channels = 3
    args.state_dim = 32*32
else:
    args.channels = 1
    args.state_dim = 32*32

from torchvision import datasets, transforms
from torch.utils.data import DataLoader

from torch.distributions import Normal
def fc_init(size, init=None):
    init = init or size[0]
    var = 1./np.sqrt(init)
    n = Normal(0, var)
    return n.sample(size)


trans = transforms.Compose([
    transforms.Resize(32),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,)),
])
mnist_train = datasets.MNIST("../data", train=True, download=True, transform=trans)
mnist_test = datasets.MNIST("../data", train=False, download=True, transform=trans)
train_loader = DataLoader(mnist_train, batch_size=args.batch_size, shuffle=True)
test_loader = DataLoader(mnist_test, batch_size=args.batch_size, shuffle=False)


class Flatten(nn.Module):
    def forward(self, x):
        return x.view(x.shape[0], -1)


model_dnn_2 = nn.Sequential(
    Flatten(), nn.Linear(784, 200), nn.ReLU(),
    nn.Linear(200, 10)).to(device)

model_dnn_4 = nn.Sequential(
    Flatten(), nn.Linear(784, 200), nn.ReLU(),
    nn.Linear(200, 100), nn.ReLU(),
    nn.Linear(100, 100), nn.ReLU(),
    nn.Linear(100, 10)).to(device)

# model_cnn = nn.Sequential(
#     nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),
#     nn.Conv2d(32, 32, 3, padding=1, stride=2), nn.ReLU(),
#     nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),
#     nn.Conv2d(64, 64, 3, padding=1, stride=2), nn.ReLU(),
#     Flatten(),
#     nn.Linear(7 * 7 * 64, 100), nn.ReLU(),
#     nn.Linear(100, 10)).to(device)


def fgsm(model, X, y, epsilon=0.1):
    """ Construct FGSM adversarial examples on the examples X"""
    delta = torch.zeros_like(X, requires_grad=True)
    loss = nn.CrossEntropyLoss()(model(X + delta), y)
    loss.backward()
    return epsilon * delta.grad.detach().sign()


def pgd_linf(model, X, y, epsilon=0.1, alpha=0.01, num_iter=20, randomize=False):
    """ Construct FGSM adversarial examples on the examples X"""
    if randomize:
        delta = torch.rand_like(X, requires_grad=True)
        delta.data = delta.data * 2 * epsilon - epsilon
    else:
        delta = torch.zeros_like(X, requires_grad=True)

    for t in range(num_iter):
        loss = nn.CrossEntropyLoss()(model(X + delta), y)
        loss.backward()
        delta.data = (delta + alpha * delta.grad.detach().sign()).clamp(-epsilon, epsilon)
        delta.grad.zero_()
    return delta.detach()


def epoch(loader, model, opt=None):
    """Standard training/evaluation epoch over the dataset"""
    total_loss, total_err = 0., 0.
    for X, y in loader:
        X, y = X.to(device), y.to(device)
        yp = model(X)
        loss = nn.CrossEntropyLoss()(yp, y)
        if opt:
            opt.zero_grad()
            loss.backward()
            opt.step()
        total_err += (yp.max(dim=1)[1] != y).sum().item()
        total_loss += loss.item() * X.shape[0]
    return total_err / len(loader.dataset), total_loss / len(loader.dataset)


# from DDPG import Actor
# from AE_MINIST import Autoencoder
# from GAN_MINIST import Generator, Discriminator
# from pretrained_model.model_DDPG import DDPG
summary_writer = SummaryWriter(log_dir='./runs/', comment='scalar')
from ddpg import DDPG
from models.wgan_gradient_penalty import Generator, Discriminator
from replay import ReplayBuffer
G = Generator(args.channels).to(device)
D = Discriminator(args.channels).to(device)

# AE = Autoencoder(args.gfv_dim).to(device)
G = Generator(args.channels).to(device)
D = Discriminator(args.channels).to(device)
# Actor = Actor(args.gfv_dim, args.z_dim, 2).to(device)
ddpg = DDPG(args.state_dim, args.z_dim, args.action_lim).to(device)
replay = ReplayBuffer()

# AE.load_state_dict(torch.load("./pretrained_model/AE_MINIST_20.pt"))
G.load_state_dict(torch.load("generator_mnist.pkl"))
D.load_state_dict(torch.load("discriminator_mnist.pkl"))
# DDPG.load_state_dict(torch.load("DDPG_MINIST_main4.pt"))


def epoch_adversarial(loader, model, attack, opt=None, **kwargs):
    """Adversarial training/evaluation epoch over the dataset"""
    total_loss, total_err = 0., 0.
    for X, y in loader:
        X, y = X.to(device), y.to(device)
        delta = attack(model, X, y, **kwargs)
        yp = model(X + delta)
        loss = nn.CrossEntropyLoss()(yp, y)
        if opt:
            opt.zero_grad()
            loss.backward()
            opt.step()

        total_err += (yp.max(dim=1)[1] != y).sum().item()
        total_loss += loss.item() * X.shape[0]
    return total_err / len(loader.dataset), total_loss / len(loader.dataset)

def imshow(img):
    #img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

def epoch_adversarial_rl(loader, model, attack, opt=None, **kwargs):
    """Adversarial training/evaluation epoch with using rl to generate the attack over the dataset"""
    total_loss, total_err = 0., 0.
    # for X, y in loader:
    #     X, y = X.to(device), y.to(device)

    train_loader_iterator = iter(loader)
    for t in range(len(train_loader_iterator)):
        # print('!!!!!!!!!!!!!!!', t, len(train_loader_iterator))
        try:
            data = next(train_loader_iterator)
        except StopIteration:
            train_loader_iterator = iter(train_loader)
            data = next(train_loader_iterator)
        X, y = data
        X = X.to(device)
        img = X.view(1, -1)
        # tmp = img.cpu()
        # print('!!!!!!!!!!!!!!!', tmp[0, 70:100])
        # imshow(torchvision.utils.make_grid(tmp[:3]))
        # torchvision.utils.save_image(X, 'original_img{}.png'.format(t))
        img = Variable(img).to(device)
        y = y.to(device)
        # with torch.no_grad():
        #     state_t = AE.encode(img)
        state_t = img

        for stp in range(args.num_steps):
            #  calculate the action
            if t < args.start_time:
                action_t = args.action_lim * torch.randn(1, args.z_dim)
                action_t = action_t.to(device)
            else:
                action_t = ddpg.choose_action(state_t).detach() + 0.01 * torch.randn(1, args.z_dim).to(device)
                # action_t = ddpg.choose_action(state_t) + 0.05*torch.randn(1, action_dim).to(device).numpy()
                action_t = action_t.clamp(-args.action_lim, args.action_lim)

            action_t = action_t.unsqueeze(2)
            action_t = action_t.unsqueeze(3)


            fake_img = G(action_t)

            yp = model(fake_img)
            loss = nn.CrossEntropyLoss()(yp, y)
            reward_accu = loss
            # print('original l')

            fake_img_state = fake_img.view(args.batch_size, -1)
            # calculate the reward
            # reward_gfv = -torch.mean(torch.pow(fake_state - state_t, 2), dim=-1, keepdim=True)
            # reward_gfv = -F.mse_loss(fake_state, state_t)

            # reward_gfv = -F.mse_loss(fake_img_state, img)
            reward_gfv = -F.mse_loss(fake_img_state, state_t)
            # print('!!!!!!!!!!!!!!!!!!!!!!', reward_gfv)
            with torch.no_grad():
                reward_disc = D(fake_img)
                # print('!!!!!!!!!!!!!!!!!!!!!!', reward_disc)
            reward_disc = 1e-3*torch.mean(reward_disc)
            reward_gfv = args.alpha*reward_gfv
            reward_accu = args.beta*reward_accu
            # print('!!!!!!!!!!!!!!!!!!!!!!', reward_accu)
            reward = reward_gfv + reward_accu

            next_state = fake_img_state
            replay.add_(state_t, action_t, reward, next_state, None)
            state_t = next_state
            if t % 1000 == 0:
                if stp == 1:
                    # print('Iter : {}, Reward : {:.4f}, GFV: {:.4f}, Disc: {:.4f}, Action: {}'.format(t, reward, reward_gfv, reward_disc, action_t))
                    print('Iter : ', t, 'Reward%.3f:' %reward.item(), 'GFV reward%.3f:' %reward_gfv.item(), 'dic Reward%.3f:' %reward_disc.item(), 'acc Reward %.3f:' %reward_accu.item())
            if t > args.start_time:
                ddpg.learn(replay_buffer=replay, episodes=t, batch_size=100, gamma=0.99, tau=0.005, learn_freq=20)
                summary_writer.add_scalar('train total reward', reward, t)
                summary_writer.add_scalar('train gfv reward', reward_gfv, t)
                summary_writer.add_scalar('train discriminator reward', reward_disc, t)
                summary_writer.add_scalar('CriticLoss', ddpg.critic_loss.clone().cpu().data.numpy(), t)
        torch.save(ddpg.state_dict(), 'DDPG-model-rl-mnist-4.pt')
        # ddpg.save()
        # summary_writer.close()

        if opt:
            if t > args.start_time_classfier:
                if t%1000 == 0:
                    print('update clssifier!!!!!!!!!!!!!!!!!!')
                opt.zero_grad()
                loss.backward()
                opt.step()
        total_err += (yp.max(dim=1)[1] != y).sum().item()
        total_loss += loss.item() * img.shape[0]
    summary_writer.close()
    return total_err / len(loader.dataset), total_loss / len(loader.dataset)


import torch.optim as optim


class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()

        self.conv_layer = nn.Sequential(

            # Conv Layer block 1
            nn.Conv2d(in_channels=args.channels, out_channels=32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.LeakyReLU(),
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
            nn.LeakyReLU(),
            nn.AvgPool2d(kernel_size=2, stride=2),

            # Conv Layer block 2
            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(),
            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),
            nn.LeakyReLU(),
            nn.AvgPool2d(kernel_size=2, stride=2),

            # Conv Layer block 3
            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(),
            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),
            nn.LeakyReLU(),
            nn.AvgPool2d(kernel_size=2, stride=2),
        )

        self.fc_layer = nn.Sequential(
            nn.Linear(4096, 1024),
            nn.ReLU(),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Dropout(p=0.2),
            nn.Linear(512, 10)
        )

    def forward(self, x):
        # conv layers
        x = self.conv_layer(x)

        # flatten
        x = x.view(x.size(0), -1)

        # fc layer
        x = self.fc_layer(x)

        return x

model_cnn = CNN().to(device)
model_cnn.load_state_dict(torch.load("pretrained_classifier_mnist.pt"))
cnn_opt = optim.SGD(model_cnn.parameters(), lr=args.lr_cnn, momentum=0.9)
# Train with rl generated adversarial attack~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
for t in range(args.num_epoch):
    # train_err, train_loss = epoch_adversarial_rl(train_loader, model_cnn, pgd_linf, cnn_opt)
    # test_err, test_loss = epoch(test_loader, model_cnn)
    # adv_err, adv_loss = epoch_adversarial(test_loader, model_cnn, pgd_linf)
    train_err, train_loss = epoch_adversarial_rl(train_loader, model_cnn, pgd_linf)
    if t == 4:
        for param_group in cnn_opt.param_groups:
            param_group["lr"] = 5e-2
    # print(*("{:.6f}".format(i) for i in (train_err, test_err, adv_err)), sep="\t")
torch.save(model_cnn.state_dict(), "model-main-rl-mnist-4.pt")

